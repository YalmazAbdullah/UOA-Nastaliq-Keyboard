---
title: "Experiments"
output: html_document
---

# Experiments

```{r, echo=FALSE}
# install.packages("kableExtra")
# install.packages("languageR")
# install.packages("MASS")
# install.packages("WRS2")
library(tidyverse)
library(rstatix)
library(ggplot2)
library(ggpubr)
library(knitr)
library(MASS)
library("WRS2")
library(kableExtra)
knitr::opts_knit$set(root.dir = "~/UOA-Nastaliq-Keyboard/DiscountEvaluation/src_r/")
```

```{r}
#data1_unigram <- read.csv("../data/monad/dakshina_dataset.csv")
#data1_bigram <- read.csv("../data/dyad/dakshina_dataset.csv")
#data1_sentence <- read.csv("../data/sentence/score/dakshina_dataset.csv")
#data1_levenshtine <- read.csv("../data/sentence/distance/dakshina_dataset.csv")

#data2_unigram <- read.csv("../data/monad/roUrParl_dataset.csv")
#data2_bigram <- read.csv("../data/dyad/roUrParl_dataset.csv")
#data2_sentence <- read.csv("../data/sentence/score/roUrParl_dataset.csv")
#data2_levenshtine <- read.csv("../data/sentence/distance/roUrParl_dataset.csv")

data3_unigram <- read.csv("../data/monad/combined_dataset.csv")
data3_bigram <- read.csv("../data/dyad/combined_dataset.csv")
data3_sentence <- read.csv("../data/sentence/score/combined_dataset.csv")
data3_levenshtine <- read.csv("../data/sentence/distance/combined_dataset.csv")
```

```{r, echo=FALSE}
# Calculating some additional stuff for help in analysis
combine_fingers <- function(df) {
  # Combined finger press
  df$Press_Little <- df$Press_L_Little + df$Press_R_Little
  df$Press_Ring   <- df$Press_L_Ring   + df$Press_R_Ring
  df$Press_Middle <- df$Press_L_Middle + df$Press_R_Middle
  df$Press_Index  <- df$Press_L_Index  + df$Press_R_Index
  
  # Combined finger distance
  df$Dist_Little  <- df$Dist_L_Little + df$Dist_R_Little
  df$Dist_Ring    <- df$Dist_L_Ring   + df$Dist_R_Ring
  df$Dist_Middle  <- df$Dist_L_Middle + df$Dist_R_Middle
  df$Dist_Index   <- df$Dist_L_Index  + df$Dist_R_Index
  
  # Combined hand press
  df$Press_L <- df$Press_L_Little + df$Press_L_Ring + df$Press_L_Middle + df$Press_L_Index
  df$Press_R <- df$Press_R_Little + df$Press_R_Ring + df$Press_R_Middle + df$Press_R_Index
  
  # Combined hand distance
  df$Dist_L <- df$Dist_L_Little + df$Dist_L_Ring + df$Dist_L_Middle + df$Dist_L_Index
  df$Dist_R <- df$Dist_R_Little + df$Dist_R_Ring + df$Dist_R_Middle + df$Dist_R_Index
  
  # Total press
  df$Press <- df$Press_L + df$Press_R
  
  # Total distance
  df$Dist <- df$Dist_L + df$Dist_R
  return(df)
}

#data1_bigram<-combine_fingers(data1_bigram)
#data2_bigram<-combine_fingers(data2_bigram)
data3_bigram<-combine_fingers(data3_bigram)

#data1_sentence<-combine_fingers(data1_sentence)
#data2_sentence<-combine_fingers(data2_sentence)
data3_sentence<-combine_fingers(data3_sentence)
```

```{r, echo=FALSE}
# Some set up.
mapping <- c("L_Little" = "Little", "R_Little" = "Little",
             "L_Ring"   = "Ring",   "R_Ring"   = "Ring",
             "L_Middle" = "Middle", "R_Middle" = "Middle",
             "L_Index"  = "Index",  "R_Index"  = "Index")
data3_unigram$FingerCombined <- mapping[match(data3_unigram$Finger, names(mapping))]
data3_unigram$FingerCombined = factor(data3_unigram$FingerCombined, levels = c("Little", "Ring", "Middle","Index"), ordered = TRUE)

data3_sentence_long <- data3_sentence %>%
  gather(key = "Finger", value = "Dist", Dist_Little, Dist_Ring, Dist_Middle, Dist_Index) %>%
  convert_as_factor(X, Finger)
data3_sentence_long$Finger <- factor(data3_sentence_long$Finger, levels = c("Dist_Little", "Dist_Ring", "Dist_Middle", "Dist_Index"))
```

## Examining Correction Options

We can use Box Cox to identify what transformation would appropriate.

```{r,echo=FALSE}
data_transform <- data3_sentence_long

# Cant work with 0 values, so we use +1
data_transform$Dist <- data_transform$Dist+1

b<-boxcox(lm(data_transform$Dist ~ 1))

lambda <- b$x[which.max(b$y)]
lambda

data_transform$Dist_box<- (data_transform$Press ^ lambda - 1) / lambda
data_transform$Dist_log<- log(data_transform$Press)

ggviolin(
  data_transform, x = "Keyboard", y = "Dist_box", fill = "Finger", position = position_dodge(1)) +
  geom_boxplot(aes(x = Keyboard, y = Dist_box, group = interaction(Keyboard, Finger)),fill = "white", width = 0.1, position = position_dodge(1)) +
  scale_fill_brewer(palette = "Set2") +
  labs(x = "Keyboard", y = "Dist_box")

ggviolin(
  data_transform, x = "Keyboard", y = "Dist_log", fill = "Finger", position = position_dodge(1)) +
  geom_boxplot(aes(x = Keyboard, y = Dist_log, group = interaction(Keyboard, Finger)),fill = "white", width = 0.1, position = position_dodge(1)) +
  scale_fill_brewer(palette = "Set2") +
  labs(x = "Keyboard", y = "Dist_log")
```

The Radar Plot for box cox suggests log transformation would be most appropriate. We try both transformations (lambda calculated by box cox, and log). Plotting them shows a somewhat similar effect with log looking a little bit better? However transformations still dont seem to look promising. I tried running a two way repeated measures anova, anyway  to see if I can plot out the residuals however no matter where I looked I could not find any information on how to get residuals out of the `anova_test` function for a two way repeated measures anova.

For now

```{r,echo=FALSE, fig.width=20,fig.height=20}
ggqqplot(data_transform, "Dist_log", ggtheme = theme_bw()) +
  facet_grid(Finger ~ Keyboard, labeller = "label_both")
```

## Robust Two Way Repeated Measures ANOVA.

One problem as seen in the plots is outliers, contributing to the deviation from Gaussian. An approach taken for this kind of data in the life sciences is a Robust ANOVA. The `bwtrim` function is a mean trimming based, two way repeated measures anova that is supposed to be robust. There are two problems to this though: (1) Just like two-way repeated measures anova. I cant get the residuals from this or in any other way tell how well this method worked. (2) There seem to be multiple options for post-hoc. I tried going through them but was not able to figure out which one would be most appropriate. Details in 3rd link, pg479.

```{r, echo=FALSE}
bwtrim(Dist_log ~ Keyboard * Finger, id = ID, data = data_transform)

# Ref:

# https://www.researchgate.net/profile/Jos-Feys/post/Whats_an_alternative_to_the_Two-Way_ANOVA_for_non-parametric_data/attachment/61ecf5a8d248c650edc223f2/AS%3A1115298686078976%401642919336087/download/feys.pdf

# https://cran.r-project.org/web/packages/WRS2/vignettes/WRS2.pdf

# https://www.researchgate.net/publication/333525893_Robust_statistical_methods_in_R_using_the_WRS2_package

# https://eds-p-ebscohost-com.login.ezproxy.library.ualberta.ca/eds/detail/detail?vid=0&sid=9deb805d-6099-4267-9607-8f6cfef9d079%40redis&bdata=JnNpdGU9ZWRzLWxpdmUmc2NvcGU9c2l0ZQ%3d%3d#db=e000xna&AN=453842 (Chapter 8.6.2)

```

## Stroke Analysis Experiments

For stroke analysis I tought factor analysis might make sense. It would allow us to reduce the amount of factors, factor loadings give us an idea of the importance for each latent factor, and we can potentially identify relationships between keyboards and stroke types if we include keyboard as a factor

The problem however is repeated measures. From what I looked at this seems to be a pretty complex problem with not much consensus around an approach.
